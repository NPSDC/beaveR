% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scaleInfReps.R
\name{scaleInfReps}
\alias{scaleInfReps}
\title{Scale inferential replicate counts}
\usage{
scaleInfReps(
  tse,
  sf = NULL,
  lengthCorrect = TRUE,
  saveMeanScaled = FALSE,
  quiet = FALSE,
  force = FALSE,
  meanDepth = NULL
)
}
\arguments{
\item{tse}{a TreeSummarizedExperiment with: \code{infReps} a list of
inferential replicate count matrices, \code{counts} the
estimated counts matrix, and \code{length} the effective
lengths matrix}

\item{sf}{matrix of size factors computed for each inf replicate (default NULL)}

\item{lengthCorrect}{whether to use effective length correction
(default is TRUE)}

\item{saveMeanScaled}{store the mean of scaled inferential
replicates as an assay 'meanScaled'}

\item{quiet}{display no messages}

\item{force}{boolean to forcefully scale replicates (default FALSE)}

\item{meanDepth}{(optional) user can
specify a different mean sequencing depth. By default
the geometric mean sequencing depth is computed}
}
\value{
a TreeSummarizedExperiment with the inferential replicates
as scaledTPM with library size already corrected (no need for further
normalization). A column \code{log10mean} is also added which is the
log10 of the mean of scaled counts across all samples and all inferential
replicates.
}
\description{
A helper function to scale the inferential replicates
to the mean sequencing depth. The scaling takes into account
a robust estimator of size factor (median ratio method is used).
First, counts are corrected per row using the effective lengths
(for gene counts, the average transcript lengths), then scaled
per column to the geometric mean sequence depth, and finally are
adjusted per-column up or down by the median ratio size factor to
minimize systematic differences across samples.
}
\examples{

# path to example data
dir <- system.file('extdata/brain_sim_nodtu_small_example', package='beaveR')
# path to file output by TreeTerminus
clustFile <- file.path(dir, 'cluster_nwk.txt')
# path to Salmon quantified files
quantDir <- file.path(dir, 'out_sal')
samples <- as.vector(outer(c(1:6), c(1,2), function(x,y) paste(x,y,sep='_')))
quantFiles <- file.path(quantDir, samples, 'quant.sf')
coldata <- data.frame(files=quantFiles, names=samples, condition=factor(rep(1:2, each=6)))
tse <- buildTSE(treeTermFile = clustFile, coldata = coldata)
tse <- computeSizeFactors(tse)
tse <- scaleInfReps(tse)

}
